{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e58530",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel 'Python 3 (ipykernel)'. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details. Unable to get resolved server information for ms-toolsai.jupyter:_builtin.jupyterServerUrlProvider:e3382d4e-a968-45e1-9e8b-feb9100086dd"
     ]
    }
   ],
   "source": [
    "x = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93c0ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph_builder.py\n",
    "from __future__ import annotations\n",
    "\n",
    "from typing import TypedDict, Literal, Optional, List, Dict, Any\n",
    "from typing_extensions import Annotated\n",
    "import operator\n",
    "import logging\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7513811c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from RAG_integrated.session_context import SessionContext\n",
    "from RAG_integrated.rag_functions import (\n",
    "    retrieve_hybrid_stm, \n",
    "    retrieve_hybrid_hcm, \n",
    "    retrieve_hybrid_ltm,\n",
    "    rerank_with_mmr_and_recency, \n",
    "    insert_short_term,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bcceb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Logging ----------\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "AllowedTopic = Literal[\"healthcare\", \"long-term\", \"short-term\"]\n",
    "\n",
    "# ---------- State ----------\n",
    "class GraphState(TypedDict):\n",
    "    # Inputs\n",
    "    session: SessionContext\n",
    "    input_text: str\n",
    "    qa_type: Literal[\"question\", \"statement\"]\n",
    "    topics: List[AllowedTopic]\n",
    "    candidates: Annotated[List[Dict[str, Any]], operator.add]\n",
    "    final_chunks: List[Dict[str, Any]]\n",
    "    # set True if insertion runs\n",
    "    inserted: bool\n",
    "\n",
    "\n",
    "# ---------- Nodes ----------\n",
    "\n",
    "def retrieval_node_health(state: GraphState) -> Dict[str, Any]:\n",
    "    session = state[\"session\"]\n",
    "    text = state[\"input_text\"]\n",
    "    logger.info(\"Called retrieval_node_health...\")\n",
    "    results = retrieve_hybrid_hcm(\n",
    "        engine=session.db_engine,\n",
    "        elderly_id=session.elderly_id,\n",
    "        query=text\n",
    "    )\n",
    "    logger.info(\"retrieval_node_health successful! Retrieved %d results.\", len(results))\n",
    "    return {\"candidates\": results}\n",
    "\n",
    "\n",
    "\n",
    "def retrieval_node_longterm(state: GraphState) -> Dict[str, Any]:\n",
    "    session = state[\"session\"]\n",
    "    text = state[\"input_text\"]\n",
    "    logger.info(\"Called retrieval_node_longterm...\")\n",
    "    results = retrieve_hybrid_ltm(\n",
    "        engine=session.db_engine,\n",
    "        elderly_id=session.elderly_id,\n",
    "        query=text\n",
    "    )\n",
    "    logger.info(\"retrieval_node_longterm successful! Retrieved %d results.\", len(results))\n",
    "    return {\"candidates\": results}\n",
    "\n",
    "\n",
    "\n",
    "def retrieval_node_shortterm(state: GraphState) -> Dict[str, Any]:\n",
    "    session = state[\"session\"]\n",
    "    text = state[\"input_text\"]\n",
    "    logger.info(\"Called retrieval_node_shortterm...\")\n",
    "    results = retrieve_hybrid_stm(\n",
    "        engine=session.db_engine,\n",
    "        elderly_id=session.elderly_id,\n",
    "        query=text\n",
    "    )\n",
    "    logger.info(\"retrieval_node_shortterm successful! Retrieved %d results.\", len(results))\n",
    "    return {\"candidates\": results}\n",
    "\n",
    "\n",
    "\n",
    "def reranker_node(state: GraphState) -> Dict[str, Any]:\n",
    "    session = state[\"session\"]\n",
    "    text = state[\"input_text\"]\n",
    "    candidates = state.get(\"candidates\", [])\n",
    "    logger.info(\"Called reranker_node with %d candidates...\", len(candidates))\n",
    "    chunks = rerank_with_mmr_and_recency(\n",
    "        query=text,\n",
    "        candidates=candidates,\n",
    "        cross_encoder=session.embedder\n",
    "    )\n",
    "    logger.info(\"reranker_node successful! Produced %d chunks.\", len(chunks))\n",
    "    return {\"final_chunks\": chunks}\n",
    "\n",
    "\n",
    "\n",
    "def insertion_node(state: GraphState) -> Dict[str, Any]:\n",
    "    session = state[\"session\"]\n",
    "    text = state[\"input_text\"]\n",
    "    logger.info(\"Called insertion_node...\")\n",
    "    insert_short_term(\n",
    "        engine=session.db_engine,\n",
    "        content=text,\n",
    "        embedder=session.embedder\n",
    "    )\n",
    "    logger.info(\"insertion_node successful! Inserted new content.\")\n",
    "    return {\"inserted\": True}\n",
    "\n",
    "\n",
    "# ---------- Routers ----------\n",
    "\n",
    "def qa_router(state: GraphState) -> str:\n",
    "    # Return a label used by add_conditional_edges\n",
    "    qa = state[\"qa_type\"]\n",
    "    return \"question\" if qa == \"question\" else \"statement\"\n",
    "\n",
    "def topics_router(state: GraphState) -> List[str]:\n",
    "    # fan-out across selected topics\n",
    "    # return a list of labels that map to nodes\n",
    "    # ensures topics are valid and de-duplicated\n",
    "    seen = set()\n",
    "    selected: List[str] = []\n",
    "    for t in state.get(\"topics\", []):\n",
    "        if t in (\"healthcare\", \"long-term\", \"short-term\") and t not in seen:\n",
    "            selected.append(t)\n",
    "            seen.add(t)\n",
    "    # Always have at least one by your contract; if not, you could default/raise.\n",
    "    return selected\n",
    "\n",
    "def statement_fork_router(state: GraphState) -> List[str]:\n",
    "    # For \"statement\", we run insertion AND retrieval in parallel.\n",
    "    # We return two labels so the scheduler launches both branches.\n",
    "    return [\"do_insertion\", \"route_topics_for_statement\"]\n",
    "\n",
    "\n",
    "# ---------- Subgraph Builders ----------\n",
    "\n",
    "def build_retrieval_subgraph(name_prefix: str = \"\") -> StateGraph[GraphState]:\n",
    "    \"\"\"\n",
    "    Builds a mini-graph that:\n",
    "      topics_router -> topic-specific retrieval nodes (in parallel) -> rerank\n",
    "    \"\"\"\n",
    "    g = StateGraph(GraphState)\n",
    "    # Nodes\n",
    "    g.add_node(f\"{name_prefix}topics_router\", topics_router)  # router node (returns list)\n",
    "    g.add_node(f\"{name_prefix}retrieve_healthcare\", retrieval_node_health)\n",
    "    g.add_node(f\"{name_prefix}retrieve_long_term\", retrieval_node_longterm)\n",
    "    g.add_node(f\"{name_prefix}retrieve_short_term\", retrieval_node_shortterm)\n",
    "    g.add_node(f\"{name_prefix}rerank\", reranker_node)\n",
    "\n",
    "    # Fan-out per topic\n",
    "    g.add_conditional_edges(\n",
    "        f\"{name_prefix}topics_router\",\n",
    "        topics_router,\n",
    "        {\n",
    "            \"healthcare\": f\"{name_prefix}retrieve_healthcare\",\n",
    "            \"long-term\": f\"{name_prefix}retrieve_long_term\",\n",
    "            \"short-term\": f\"{name_prefix}retrieve_short_term\",\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # Fan-in to rerank\n",
    "    g.add_edge(f\"{name_prefix}retrieve_healthcare\", f\"{name_prefix}rerank\")\n",
    "    g.add_edge(f\"{name_prefix}retrieve_long_term\", f\"{name_prefix}rerank\")\n",
    "    g.add_edge(f\"{name_prefix}retrieve_short_term\", f\"{name_prefix}rerank\")\n",
    "\n",
    "    # Entrypoint and exit\n",
    "    g.add_edge(START, f\"{name_prefix}topics_router\")\n",
    "    g.add_edge(f\"{name_prefix}rerank\", END)\n",
    "\n",
    "    return g\n",
    "\n",
    "\n",
    "def build_insertion_subgraph(name_prefix: str = \"\") -> StateGraph[GraphState]:\n",
    "    \"\"\"\n",
    "    Simple insertion node. If you later want topic-based insertion, copy the\n",
    "    retrieval fan-out pattern here as well.\n",
    "    \"\"\"\n",
    "    g = StateGraph(GraphState)\n",
    "    g.add_node(f\"{name_prefix}insert\", insertion_node)\n",
    "    g.add_edge(START, f\"{name_prefix}insert\")\n",
    "    g.add_edge(f\"{name_prefix}insert\", END)\n",
    "    return g\n",
    "\n",
    "\n",
    "# ---------- Unified Graph ----------\n",
    "\n",
    "def build_unified_graph() -> Any:\n",
    "    \"\"\"\n",
    "    Unified graph:\n",
    "      - If qa == 'question': run Retrieval DAG only.\n",
    "      - If qa == 'statement': run Insertion AND Retrieval in parallel.\n",
    "    \"\"\"\n",
    "    # Subgraphs\n",
    "    retrieval = build_retrieval_subgraph(\"q_\")      # question retrieval flow\n",
    "    retrieval_stmt = build_retrieval_subgraph(\"s_\") # statement retrieval flow (identical, separate namespace)\n",
    "    insertion = build_insertion_subgraph(\"s_\")      # statement insertion flow\n",
    "\n",
    "    g = StateGraph(GraphState)\n",
    "\n",
    "    # Mount subgraphs as nodes\n",
    "    g.add_node(\"retrieval_question\", retrieval.compile())\n",
    "    g.add_node(\"retrieval_statement\", retrieval_stmt.compile())\n",
    "    g.add_node(\"insertion_statement\", insertion.compile())\n",
    "\n",
    "    # Routers\n",
    "    g.add_node(\"qa_router\", qa_router)\n",
    "    g.add_node(\"statement_fork_router\", statement_fork_router)\n",
    "\n",
    "    # From START, decide question vs statement\n",
    "    g.add_conditional_edges(\n",
    "        START,\n",
    "        qa_router,\n",
    "        {\n",
    "            \"question\": \"retrieval_question\",           # run retrieval-only subgraph\n",
    "            \"statement\": \"statement_fork_router\",       # then fan to insertion + retrieval\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # For statement path, fork to two branches in parallel\n",
    "    g.add_conditional_edges(\n",
    "        \"statement_fork_router\",\n",
    "        statement_fork_router,\n",
    "        {\n",
    "            \"do_insertion\": \"insertion_statement\",\n",
    "            \"route_topics_for_statement\": \"retrieval_statement\",\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # Where do we end?\n",
    "    # Both subgraphs individually end in END, so after both branches complete,\n",
    "    # the unified graph will be done.\n",
    "    # (No extra edges needed; the scheduler handles parallelism + completion.)\n",
    "\n",
    "    compiled = g.compile()\n",
    "    return compiled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35930d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Example usage ----------\n",
    "\n",
    "# def run_example(session: SessionContext):\n",
    "#     graph = build_unified_graph()\n",
    "#     # QUESTION example\n",
    "#     out_q = graph.invoke({\n",
    "#         \"session\": session,\n",
    "#         \"input_text\": \"What meds are currently prescribed?\",\n",
    "#         \"qa_type\": \"question\",\n",
    "#         \"topics\": [\"healthcare\", \"short-term\"],\n",
    "#         \"candidates\": [],\n",
    "#         \"final_chunks\": [],\n",
    "#         \"inserted\": False,\n",
    "#     })\n",
    "#     # STATEMENT example\n",
    "#     out_s = graph.invoke({\n",
    "#         \"session\": session,\n",
    "#         \"input_text\": \"Add note: medication taken at 9:00 PM.\",\n",
    "#         \"qa_type\": \"statement\",\n",
    "#         \"topics\": [\"short-term\"],\n",
    "#         \"candidates\": [],\n",
    "#         \"final_chunks\": [],\n",
    "#         \"inserted\": False,\n",
    "#     })\n",
    "#     return out_q, out_s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
