{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45b9da30",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c179570b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c01ea06",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3a0cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\leege\\Documents\\Capstone\\elderly_topical_conversational_sentences.csv\")\n",
    "\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33f79b9",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc91f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "HEALTHCARE_KEYWORDS = [\n",
    "    \"clinic\", \"polyclinic\", \"hospital\", \"doctor\", \"nurse\", \"medicine\",\n",
    "    \"tablet\", \"capsule\", \"injection\", \"pain\", \"ache\", \"symptom\",\n",
    "    \"treatment\", \"checkup\", \"appointment\", \"blood pressure\", \"diabetes\",\n",
    "    \"cholesterol\", \"physiotherapy\", \"rehabilitation\", \"pharmacy\", \"scan\",\n",
    "    \"surgery\", \"therapy\", \"consultation\", \"vaccination\", \"prescription\"\n",
    "]\n",
    "\n",
    "LONGTERM_KEYWORDS = [\n",
    "    \"grandson\", \"granddaughter\", \"children\", \"family\", \"siblings\", \"parents\",\n",
    "    \"hobby\", \"gardening\", \"reading\", \"knitting\", \"painting\", \"cooking\",\n",
    "    \"house\", \"flat\", \"HDB\", \"condo\", \"car\", \"pet\", \"cat\", \"dog\",\n",
    "    \"garden\", \"relatives\", \"friends\", \"community\", \"club\", \"volunteer\",\n",
    "    \"retirement\", \"savings\", \"pension\"\n",
    "]\n",
    "\n",
    "SHORTTERM_KEYWORDS = [\n",
    "    \"today\", \"tomorrow\", \"later\", \"now\", \"yesterday\", \"tonight\",\n",
    "    \"MRT\", \"bus\", \"train\", \"hawker\", \"hawker centre\", \"kopitiam\",\n",
    "    \"wet market\", \"supermarket\", \"shop\", \"shopping\", \"meal\", \"breakfast\",\n",
    "    \"lunch\", \"dinner\", \"snack\", \"queue\", \"appointment\", \"errand\", \"weather\",\n",
    "    \"rain\", \"sunny\", \"hot\", \"cold\", \"event\", \"celebration\", \"CNY\", \"angbao\",\n",
    "    \"getai\", \"festival\", \"promotion\", \"sale\", \"traffic\", \"delay\", \"jam\"\n",
    "]\n",
    "\n",
    "def count_category_words(text, category_words):\n",
    "    \"\"\"Count how many words in `text` match `category_words` (case-insensitive).\"\"\"\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    return sum(1 for w in words if w in category_words)\n",
    "\n",
    "def add_category_word_counts(df):\n",
    "    df = df.copy()  # Avoid modifying original df\n",
    "    df['healthcare_count'] = df['text'].apply(lambda x: count_category_words(x, HEALTHCARE_KEYWORDS))\n",
    "    df['longterm_count'] = df['text'].apply(lambda x: count_category_words(x, LONGTERM_KEYWORDS))\n",
    "    df['shortterm_count'] = df['text'].apply(lambda x: count_category_words(x, SHORTTERM_KEYWORDS))\n",
    "    return df\n",
    "\n",
    "df = add_category_word_counts(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0f659c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Extraction with tf-idf\n",
    "X_text = df['text'].values\n",
    "y_text = df['label'].values\n",
    "\n",
    "# Encode text labels to integers\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y_text)\n",
    "print(\"Label mapping:\", dict(zip(le.classes_, range(len(le.classes_)))))\n",
    "\n",
    "# TF-IDF features\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=500, ngram_range=(1,2))\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(X_text).toarray()\n",
    "\n",
    "# SBERT embeddings\n",
    "# all-MiniLM-L6-v2 or all-mpnet-base-v2\n",
    "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "X_sbert = sbert_model.encode(X_text, show_progress_bar=True)\n",
    "\n",
    "# Categorical features\n",
    "category_features = df[['healthcare_count', 'longterm_count', 'shortterm_count']].values\n",
    "\n",
    "# Combine all features\n",
    "X_hybrid = np.hstack([X_tfidf, X_sbert, category_features])\n",
    "print(\"Hybrid feature shape:\", X_hybrid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f5d631",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d062c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Validation/Test Split\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X_hybrid, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size=0.25, random_state=42)\n",
    "\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=427,\n",
    "    max_depth=9,\n",
    "    learning_rate=0.033,\n",
    "    min_child_weight=1,\n",
    "    gamma=0.179,\n",
    "    subsample=0.748,\n",
    "    colsample_bytree=0.63,\n",
    "    reg_alpha=0.225,\n",
    "    reg_lambda=0.69,\n",
    "    eval_metric='mlogloss',  # multi-class logloss\n",
    "    objective='multi:softprob',  # multi-class\n",
    "    num_class=3,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae1746a",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8ff29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# --- Predict on test set ---\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# --- Accuracy ---\n",
    "print(\"Test accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# --- Classification report with original labels ---\n",
    "print(\"\\nClassification Report:\\n\", \n",
    "      classification_report(y_test, y_pred, target_names=le.classes_))\n",
    "\n",
    "# --- Confusion matrix ---\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\\n\", cm)\n",
    "\n",
    "# Optional: normalized confusion matrix\n",
    "cm_norm = confusion_matrix(y_test, y_pred, normalize='true')\n",
    "print(\"\\nNormalized Confusion Matrix:\\n\", cm_norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d773e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# Define category keywords (should match training)\n",
    "HEALTHCARE_KEYWORDS = [\n",
    "    \"clinic\",\"polyclinic\",\"hospital\",\"doctor\",\"nurse\",\"medicine\",\n",
    "    \"tablet\",\"capsule\",\"injection\",\"pain\",\"ache\",\"symptom\",\n",
    "    \"treatment\",\"checkup\",\"appointment\",\"blood pressure\",\"diabetes\",\n",
    "    \"cholesterol\",\"physiotherapy\",\"rehabilitation\",\"pharmacy\",\"scan\",\n",
    "    \"surgery\",\"therapy\",\"consultation\",\"vaccination\",\"prescription\"\n",
    "]\n",
    "\n",
    "LONGTERM_KEYWORDS = [\n",
    "    \"grandson\",\"granddaughter\",\"children\",\"family\",\"siblings\",\"parents\",\n",
    "    \"hobby\",\"gardening\",\"reading\",\"knitting\",\"painting\",\"cooking\",\n",
    "    \"house\",\"flat\",\"HDB\",\"condo\",\"car\",\"pet\",\"cat\",\"dog\",\n",
    "    \"garden\",\"relatives\",\"friends\",\"community\",\"club\",\"volunteer\",\n",
    "    \"retirement\",\"savings\",\"pension\"\n",
    "]\n",
    "\n",
    "SHORTTERM_KEYWORDS = [\n",
    "    \"today\",\"tomorrow\",\"tonight\",\"now\",\"yesterday\",\"morning\",\"afternoon\",\"evening\",\n",
    "    \"MRT\",\"bus\",\"train\",\"hawker\",\"hawker centre\",\"kopitiam\",\"wet market\",\n",
    "    \"supermarket\",\"shop\",\"shopping\",\"meal\",\"breakfast\",\"lunch\",\"dinner\",\"snack\",\n",
    "    \"queue\",\"appointment\",\"errand\",\"weather\",\"rain\",\"sunny\",\"hot\",\"cold\",\"event\",\n",
    "    \"celebration\",\"CNY\",\"angbao\",\"getai\",\"festival\",\"promotion\",\"sale\",\"traffic\",\n",
    "    \"delay\",\"jam\"\n",
    "]\n",
    "\n",
    "def count_category_words(text, category_words):\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    return sum(1 for w in words if w in category_words)\n",
    " \n",
    "def predict_text(new_texts, le):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "        new_texts: list of strings\n",
    "        le: trained LabelEncoder\n",
    "    Output: predicted labels as original text (e.g., 'healthcare', 'long-term', 'short-term')\n",
    "    \"\"\"\n",
    "    \n",
    "    # TF-IDF and SBERT\n",
    "    X_tfidf_new = tfidf_vectorizer.transform(new_texts).toarray()\n",
    "    X_sbert_new = sbert_model.encode(new_texts, show_progress_bar=False)\n",
    "    X_nlp_new = np.array([extract_simple_nlp_features(t) for t in new_texts])\n",
    "    \n",
    "    # Category word counts\n",
    "    category_features_new = np.array([\n",
    "        [\n",
    "            count_category_words(t, HEALTHCARE_KEYWORDS),\n",
    "            count_category_words(t, LONGTERM_KEYWORDS),\n",
    "            count_category_words(t, SHORTTERM_KEYWORDS)\n",
    "        ]\n",
    "        for t in new_texts\n",
    "    ])\n",
    "    \n",
    "    # Combine all features\n",
    "    X_new_hybrid = np.hstack([X_tfidf_new, X_sbert_new, category_features_new])\n",
    "    \n",
    "    # Predict integers\n",
    "    preds_int = xgb_model.predict(X_new_hybrid)\n",
    "    \n",
    "    # Convert back to original labels\n",
    "    preds_text = le.inverse_transform(preds_int)\n",
    "    return preds_text\n",
    "\n",
    "# Example usage\n",
    "predict_text([\"Forget eat medicine again\"],le)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3594c6",
   "metadata": {},
   "source": [
    "# Save model (Change directory accordingly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7592f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save models\n",
    "with open(\"topic_xgb_hybrid_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(xgb_model, f)\n",
    "\n",
    "with open(\"topic_tfidf_vectorizer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tfidf_vectorizer, f)\n",
    "\n",
    "with open(\"topic_sbert_model_name.pkl\", \"wb\") as f:\n",
    "    pickle.dump('all-MiniLM-L6-v2', f)\n",
    "\n",
    "with open('topic_label_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(le, f)\n",
    "    \n",
    "with open('topic_category_keywords.pkl', 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'healthcare': HEALTHCARE_KEYWORDS,\n",
    "        'longterm': LONGTERM_KEYWORDS,\n",
    "        'shortterm': SHORTTERM_KEYWORDS\n",
    "    }, f)\n",
    "\n",
    "print(\"Models and artifacts saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c61c28",
   "metadata": {},
   "source": [
    "# Randomized Search - Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1aa7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform, randint\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': randint(100, 600),\n",
    "    'max_depth': randint(3, 10),\n",
    "    'learning_rate': uniform(0.01, 0.2),\n",
    "    'min_child_weight': randint(1, 6),\n",
    "    'gamma': uniform(0, 0.5),\n",
    "    'subsample': uniform(0.6, 0.4),\n",
    "    'colsample_bytree': uniform(0.6, 0.4),\n",
    "    'reg_alpha': uniform(0, 0.5),\n",
    "    'reg_lambda': uniform(0.5, 2)\n",
    "}\n",
    "\n",
    "xgb_model = XGBClassifier(\n",
    "    objective='multi:softprob',  # multi-class\n",
    "    num_class=3,\n",
    "    eval_metric='mlogloss',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=15,\n",
    "    scoring='accuracy',\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Score\n",
    "print(\"Best parameters found:\", random_search.best_params_)\n",
    "print(\"Best CV accuracy:\", random_search.best_score_)\n",
    "\n",
    "# Eval\n",
    "best_model = random_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(\"Test accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
