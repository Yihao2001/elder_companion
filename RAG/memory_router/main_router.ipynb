{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d5d3151",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3440c211",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "import pickle\n",
    "import numpy as np\n",
    "import re\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea1ec09",
   "metadata": {},
   "source": [
    "# Load QA-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0252e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"model_weights/qa_xgb_hybrid_model.pkl\", \"rb\") as f:\n",
    "    xgb_model_qa = pickle.load(f)\n",
    "\n",
    "with open(\"model_weights/qa_tfidf_vectorizer.pkl\", \"rb\") as f:\n",
    "    tfidf_vectorizer_qa = pickle.load(f)\n",
    "\n",
    "with open(\"model_weights/qa_sbert_model_name.pkl\", \"rb\") as f:\n",
    "    sbert_model_name = pickle.load(f)\n",
    "    sbert_model_qa = SentenceTransformer(sbert_model_name)\n",
    "\n",
    "def prepare_features_qa(texts):\n",
    "\n",
    "    question_words = ['who','what','where','when','why','how','which']\n",
    "    def extract_simple_nlp_features(text):\n",
    "        words = text.lower().split()\n",
    "        return np.array([\n",
    "            int(text.lower().endswith('?')),                      \n",
    "            int(words[0] in question_words if words else 0)\n",
    "        ])\n",
    "        \n",
    "    X_tfidf_new = tfidf_vectorizer_qa.transform(texts).toarray()\n",
    "    X_sbert_new = sbert_model_qa.encode(texts, show_progress_bar=False)\n",
    "    X_nlp_new = np.array([extract_simple_nlp_features(t) for t in texts])\n",
    "    \n",
    "    return np.hstack([X_tfidf_new, X_sbert_new, X_nlp_new])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c068803",
   "metadata": {},
   "source": [
    "# Load Topic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d1f27df",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"model_weights/topic_xgb_hybrid_model.pkl\", \"rb\") as f:\n",
    "    xgb_model_topic = pickle.load(f)\n",
    "\n",
    "with open(\"model_weights/topic_tfidf_vectorizer.pkl\", \"rb\") as f:\n",
    "    tfidf_vectorizer_topic = pickle.load(f)\n",
    "\n",
    "with open(\"model_weights/topic_sbert_model_name.pkl\", \"rb\") as f:\n",
    "    sbert_model_name = pickle.load(f)\n",
    "    sbert_model_topic = SentenceTransformer(sbert_model_name)\n",
    "\n",
    "with open(\"model_weights/topic_label_encoder.pkl\", \"rb\") as f:\n",
    "    le_topic = pickle.load(f)\n",
    "\n",
    "with open(\"model_weights/topic_category_keywords.pkl\", \"rb\") as f:\n",
    "    CATEGORY_KEYWORDS = pickle.load(f)\n",
    "\n",
    "# --- Feature utilities ---\n",
    "def count_category_words_topic(text, category_words):\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    return sum(1 for w in words if w in category_words)\n",
    "\n",
    "def prepare_features_topic(texts):\n",
    "    X_tfidf = tfidf_vectorizer_topic.transform(texts).toarray()\n",
    "    X_sbert = sbert_model_topic.encode(texts, show_progress_bar=False)\n",
    "    category_features = np.array([\n",
    "        [\n",
    "            count_category_words_topic(t, CATEGORY_KEYWORDS['healthcare']),\n",
    "            count_category_words_topic(t, CATEGORY_KEYWORDS['longterm']),\n",
    "            count_category_words_topic(t, CATEGORY_KEYWORDS['shortterm'])\n",
    "        ]\n",
    "        for t in texts\n",
    "    ])\n",
    "    return np.hstack([X_tfidf, X_sbert, category_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20d1efc",
   "metadata": {},
   "source": [
    "# Make Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa682759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'When do I take my medicine?', 'topic': 'healthcare', 'qa': 'question'}\n"
     ]
    }
   ],
   "source": [
    "class State(TypedDict):\n",
    "    text: str\n",
    "    topic: str\n",
    "    qa: str\n",
    "\n",
    "def classify_text_topic(state: State) -> State:\n",
    "    text = state[\"text\"]\n",
    "    X_features = prepare_features_topic([text])\n",
    "    pred_int = xgb_model_topic.predict(X_features)\n",
    "    state[\"topic\"] = le_topic.inverse_transform(pred_int)[0]\n",
    "    return state\n",
    "\n",
    "def classify_text_qa(state: State) -> State:\n",
    "    text = state[\"text\"]\n",
    "    X_features = prepare_features_qa([text])\n",
    "    pred_int = xgb_model_qa.predict(X_features)\n",
    "    if pred_int[0] == 1:\n",
    "        state[\"qa\"] = \"question\"\n",
    "    else:\n",
    "        state[\"qa\"] = \"statement\"\n",
    "    return state\n",
    "\n",
    "# Graph definition\n",
    "graph = StateGraph(State)\n",
    "graph.add_node(\"topic_classifier\", RunnableLambda(classify_text_topic))\n",
    "graph.add_node(\"qa_classifier\", RunnableLambda(classify_text_qa))\n",
    "graph.add_edge(START, \"topic_classifier\")\n",
    "graph.add_edge(\"topic_classifier\", \"qa_classifier\")\n",
    "graph.add_edge(\"qa_classifier\", END)\n",
    "\n",
    "# Compile\n",
    "app = graph.compile()\n",
    "\n",
    "# Example run\n",
    "result = app.invoke({\"text\": \"When do I take my medicine?\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce046c3",
   "metadata": {},
   "source": [
    "# Visualise graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95e45222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangGraph flow:\n",
      "[__start__] __start__\n",
      "[topic_classifier] topic_classifier\n",
      "[qa_classifier] qa_classifier\n",
      "[__end__] __end__\n",
      "\n",
      "Connections:\n",
      "[__start__] --> [topic_classifier]\n",
      "[topic_classifier] --> [qa_classifier]\n",
      "[qa_classifier] --> [__end__]\n"
     ]
    }
   ],
   "source": [
    "# Get nodes and edges\n",
    "nodes = app.get_graph().nodes\n",
    "edges = app.get_graph().edges\n",
    "\n",
    "print(\"LangGraph flow:\")\n",
    "\n",
    "# Print nodes\n",
    "for node_id, node in nodes.items():\n",
    "    print(f\"[{node_id}] {node.name}\")\n",
    "\n",
    "print(\"\\nConnections:\")\n",
    "\n",
    "# Print edges (tuple style)\n",
    "for edge in edges:\n",
    "    # Each edge is a tuple: (from_node_id, to_node_id, optional_data)\n",
    "    from_id, to_id, *_ = edge\n",
    "    print(f\"[{from_id}] --> [{to_id}]\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
